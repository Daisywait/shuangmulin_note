## Source
[[周志华-机器学习_.pdf]]
> [!PDF|yellow] [[周志华-机器学习_.pdf#page=3&selection=240,0,253,1&color=yellow|周志华-机器学习_, p.3]]
> > 我们还可以对西瓜做"聚类" (clustering) ，即将训练集中的西瓜分成若干组，每组称为 A 个"簇" (cluster); 
> 
> 
[[周志华-机器学习_.pdf#page=2&selection=132,4,141,17&color=yellow|周志华-机器学习_, p.2]]
> > 如我们把"色泽" "根蒂" "敲声"作为三个坐标轴，则它们张成一个用于描述西瓜的三维空间，每个西瓜都可在这个空间中找到自己的坐标位置.由于空间中的每个点对应一个坐标向量，因此我们也把…个示例称为一个 "特征向量" (feature vector).
> 
> 
> [[周志华-机器学习_.pdf#page=2&selection=315,1,318,9&color=yellow|周志华-机器学习_, p.2]]
> > 拥有了标记信息的示例，则称为"样例" (examp1e)
> 
>
> [!PDF|yellow] [[周志华-机器学习_.pdf#page=3&selection=75,0,96,12&color=yellow|周志华-机器学习_, p.3]]
> > 若我们欲预测的是离散值，例如"好瓜" "坏瓜"，此类学习任务称为 "分类" (classification); 若欲预测的是连续值?例如西瓜成熟度 0.95 、 0.37 ， 此类学习任务称为"回归" (regression). 
> 
> 原来是这样啊，是根据预测值类型的划分

>> [!PDF|yellow] [[周志华-机器学习_.pdf#page=3&selection=262,3,266,24&color=yellow|周志华-机器学习_, p.3]]
> > 在聚类学习中，"浅色瓜" "本地瓜"这样的概念我们事先是不知道的， 而且学习过程中使用的训练样本通常不拥有标记信息.
> 
>

> [!PDF|yellow] [[周志华-机器学习_.pdf#page=3&selection=330,26,336,2&color=yellow|周志华-机器学习_, p.3]]
> > 学得模型适用于新样本的能力，称为"泛化" (generalization) 能力
> 
>

> [!PDF|] [[周志华-机器学习_.pdf#page=3&selection=342,24,359,1|周志华-机器学习_, p.3]]
> > 通常假设样本空间中全体样本服从 A 个未知"分布" (distribution) Ð ， 我们获得的每个样本都是独立地从这个分布上采样获得的，即"独立同分布"
> 
>

> [!PDF|yellow] [[周志华-机器学习_.pdf#page=4&selection=67,12,71,34&color=yellow|周志华-机器学习_, p.4]]
> >概念学习技术目前研究、应用都比较少，因为要学得泛化性能好且语义明确的概念实在太困难了，现实常用的技术大多是产生"黑箱"模型.然而，对概念学习有所了解，有助于理解机器学习的一些基础思想
> 
>
> [!PDF|yellow] [[周志华-机器学习_.pdf#page=5&selection=112,0,154,9&color=yellow|周志华-机器学习_, p.5]]
> > 这样，若"色泽" "根蒂" "敲声"分别有 3 、 2 、 2 种可能取值，则我们面临的假设空间规模大小为 4 x 3 x 3 + 1 = 37. 图1. 1 直观地显示出了这个西瓜问题假设空间.
> 
> 因为除了确定的取值，每一个都有一种取值是无论取什么值都合适，即任意取值不影响结果

> [!PDF|yellow] [[周志华-机器学习_.pdf#page=5&selection=186,29,193,1&color=yellow|周志华-机器学习_, p.5]]
> > 存在着一个与训练集一致的"假设集合"，我们称之为"版本空间" (version space).
> 
>

> [!PDF|yellow] [[周志华-机器学习_.pdf#page=6&selection=115,1,122,8&color=yellow|周志华-机器学习_, p.6]]
> > 机器学习算法在学习过程中对某种类型假设的偏好，称为"归纳偏好" (inductive bias) , 或简称为"偏好"
> 
>

> [!PDF|yellow] [[周志华-机器学习_.pdf#page=7&selection=67,0,68,13&color=yellow|周志华-机器学习_, p.7]]
> > 归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进行选择的启发式或"价值观"
> 
>

> ([[周志华-机器学习_.pdf#page=16&selection=91,1,92,23&color=red|周志华-机器学习_, p.16]])
> 机器学习研究还有另一个不可忽视的意义，即通过建立一些关于学习的计算模型来促进我们理解"人类如何学习"


![[周志华-机器学习_.pdf#page=8&rect=169,218,503,263|周志华-机器学习_, p.8]]

> ([[周志华-机器学习_.pdf#page=9&selection=105,1,110,22&color=yellow|周志华-机器学习_, p.9]])
> NFL 定理有一个重要前提:所有"问题"出现的机会相同、或所有问题同等重要.但实际情形并不是这样
> ([[周志华-机器学习_.pdf#page=9&selection=200,1,205,20&color=red|周志华-机器学习_, p.9]])
> NFL 走理最重要的寓意?是让我们清楚地认识到，脱离具体问题，空泛地谈论"什么学习算法更好"毫无意义，因


