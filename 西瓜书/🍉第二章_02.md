![[周志华-机器学习_.pdf#page=31&rect=175,227,508,423|周志华-机器学习_, p.31]]
> [!PDF|] [[周志华-机器学习_.pdf#page=31&selection=250,2,271,10|周志华-机器学习_, p.31]]
> > 若一个学习器的 P-R 曲线被另一个学习器的曲线完全"包住 " ， 则可断言后者的性能优于前者，
> 
> > [!PDF|] [[周志华-机器学习_.pdf#page=31&selection=360,0,379,1|周志华-机器学习_, p.31]]
> > 这时一个比较合理的判据是比较 P-R 曲线节面积的大小，它在一定程度上表征了学习器在查准率和查全率上取得相对"双高"的比例
> 
> > [!PDF|] [[周志华-机器学习_.pdf#page=31&selection=404,1,433,1|周志华-机器学习_, p.31]]
> > 平衡点 " (Break-Event Point ，简称 BEP) 就是这样一个度量，它是" 查准率= 查全率"时的取值 
> 
> ![[周志华-机器学习_.pdf#page=32&rect=60,431,158,504|周志华-机器学习_, p.32]]![[周志华-机器学习_.pdf#page=32&rect=167,365,501,432|周志华-机器学习_, p.32]]

> [!PDF|yellow] [[周志华-机器学习_.pdf#page=33&selection=105,0,109,17&color=yellow|周志华-机器学习_, p.33]]
> > 在不同的应用任务中，我们可根据任务需求来采用不同的截断点，例如若我们更重视"查准率"，则可选择排序中靠前的位置进行截断;若更重视"查全率"，则可选择靠后的位置进行截断

![[周志华-机器学习_.pdf#page=33&rect=159,24,513,145|周志华-机器学习_, p.33]]> [!PDF|yellow] [[周志华-机器学习_.pdf#page=34&selection=366,1,388,3&color=yellow|周志华-机器学习_, p.34]]
> > 若一个学习器的 ROC 曲线被另一个学习器的曲线完全"包住"， 则可断言后者的性能优于前者;


> [!PDF|yellow] [[周志华-机器学习_.pdf#page=34&selection=421,0,456,2&color=yellow|周志华-机器学习_, p.34]]
> >  比较 ROC 曲线下的面积 ，即 A U C ( Ar ea Under ROC Curve) ，如图 2.4 所示

![[周志华-机器学习_.pdf#page=34&rect=152,329,506,521|周志华-机器学习_, p.34]]
> [!PDF|yellow] [[周志华-机器学习_.pdf#page=35&selection=167,8,171,14&color=yellow|周志华-机器学习_, p.35]]
> > 为权衡不同类型错误所造成的不同损失，可为错误赋予"非均等代价" (unequa1 cost)
> 
> ![[周志华-机器学习_.pdf#page=35&rect=71,93,166,156|周志华-机器学习_, p.35]]![[周志华-机器学习_.pdf#page=36&rect=184,375,500,493|周志华-机器学习_, p.36]]